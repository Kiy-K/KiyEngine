import argparse
import gguf
import numpy as np
from safetensors.torch import load_file
import os
import sys

def convert_to_gguf(input_path, output_path):
    print(f"ğŸ”„ Äang convert: {input_path} -> {output_path}")
    
    if not os.path.exists(input_path):
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file input: {input_path}")
        sys.exit(1)

    # 1. Load Model (Raw weights tá»« quÃ¡ trÃ¬nh train)
    print("ğŸ“¦ Äang load tensors...")
    tensors = load_file(input_path)
    
    # 2. Khá»Ÿi táº¡o GGUF Writer
    # LÆ°u Ã½: "kiyengine" lÃ  tÃªn kiáº¿n trÃºc custom Ä‘á»ƒ Rust nháº­n diá»‡n
    gguf_writer = gguf.GGUFWriter(output_path, "kiyengine")
    
    # 3. Metadata (Config cho Rust)
    print("âš™ï¸ Äang ghi Metadata...")
    gguf_writer.add_name("KiyEngine-V5-AutoSandwich")
    gguf_writer.add_block_count(4)
    gguf_writer.add_embedding_length(1024)
    gguf_writer.add_context_length(32)
    # âš ï¸ QUAN TRá»ŒNG: ÄÃ¡nh dáº¥u file lÃ  F16 Ä‘á»ƒ Rust khÃ´ng bÃ¡o lá»—i Type 48
    gguf_writer.add_file_type(gguf.LlamaFileType.MOSTLY_F16) 

    print("\nğŸ”¨ Báº®T Äáº¦U Xá»¬ LÃ & ÄÃ“NG GÃ“I (AUTO-QUANTIZATION):")
    
    for k, w in tensors.items():
        # Dá»n dáº¹p tÃªn (Fix vá»¥ _orig_mod tá»« torch.compile)
        clean_k = k.replace("_orig_mod.", "")
        
        # Chuyá»ƒn sang Numpy Ä‘á»ƒ xá»­ lÃ½ toÃ¡n há»c
        data_np = w.cpu().float().numpy() # DÃ¹ng float32 Ä‘á»ƒ tÃ­nh toÃ¡n cho chuáº©n
        
        # --- LOGIC Tá»° Äá»˜NG SANDWICH ---
        # Lá»›p áº©n: Náº±m trong 'layers', lÃ  'linear', KHÃ”NG pháº£i 'norm'
        is_hidden_layer = ("layers." in clean_k) and \
                          ("linear.weight" in clean_k) and \
                          ("norm" not in clean_k)
        
        final_data = None
        
        if is_hidden_layer:
            # === NHÃ‚N THá»ŠT (BITNET TERNARY) ===
            # Tá»± Ä‘á»™ng tÃ­nh toÃ¡n scale vÃ  Ã©p vá» {-1, 0, 1}
            scale = np.max(np.abs(data_np))
            
            if scale > 1e-6:
                # CÃ´ng thá»©c BitNet: round(w / scale).clamp(-1, 1)
                ternary = np.clip(np.round(data_np / scale), -1, 1)
            else:
                ternary = data_np # Zero tensor
            
            # LÆ°u Ã½: Rust cáº§n Ä‘á»c Float16, nÃªn ta cast vá» F16
            final_data = ternary.astype(np.float16)
            
            gguf_writer.add_tensor(clean_k, final_data)
            print(f"  ğŸ¥© {clean_k:40s} | Auto-Quantized to {-1, 0, 1} (F16 Container)")
            
        else:
            # === Vá» BÃNH (FP16 HIGH PRECISION) ===
            # Embed, Heads, Norms -> Giá»¯ nguyÃªn giÃ¡ trá»‹ thá»±c
            final_data = data_np.astype(np.float16)
            
            gguf_writer.add_tensor(clean_k, final_data)
            print(f"  ğŸ›¡ï¸ {clean_k:40s} | Giá»¯ nguyÃªn High Precision (F16)")

    # 4. Ghi file
    gguf_writer.write_header_to_file()
    gguf_writer.write_kv_data_to_file()
    gguf_writer.write_tensors_to_file()
    gguf_writer.close()
    
    print(f"\nâœ… XONG! File GGUF chuáº©n F16 Ä‘Ã£ ra lÃ²: {output_path}")
    print("ğŸ‘‰ File nÃ y chá»©a Sandwich Architecture (BitNet giá»¯a, FP16 Ä‘áº§u Ä‘uÃ´i).")
    print("ğŸ‘‰ Rust sáº½ Ä‘á»c file nÃ y 'má»™t phÃ¡t Äƒn ngay' khÃ´ng lá»—i Type 48.")

if __name__ == "__main__":
    # Giá»¯ Ä‘Ãºng interface CLI nhÆ° script gá»‘c Ã´ng yÃªu cáº§u
    parser = argparse.ArgumentParser(description="Convert KiyEngine safetensors to GGUF")
    parser.add_argument("--input", "-i", type=str, required=True, help="Path to input .safetensors file")
    parser.add_argument("--output", "-o", type=str, required=True, help="Path to output .gguf file")
    
    args = parser.parse_args()
    
    convert_to_gguf(args.input, args.output)